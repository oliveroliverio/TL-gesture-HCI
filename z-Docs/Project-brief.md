## 1. Purpose

Build a **motion-first study system for learning American Sign Language (ASL)** that prioritizes **short looping animations (2â€“3 seconds)** over static text.
The system must:

* support **embodied learning** (gesture, timing, facial grammar)
* avoid static-only formats (PDFs, audiobooks) as primary artifacts
* allow **multiple downstream presentations** (web app, Anki, PDFs, APIs)
* be **incrementally buildable** while learning ASL (no fluency prerequisite)

This project also serves as **ground-truth content infrastructure** for future gesture-based HCI research.

## 2. Core Design Principle

**Motion is the primary knowledge unit. Text is secondary metadata.**

ASL concepts are represented as **Cards**, each centered around short looping video clips.

## 3. Knowledge Atom: â€œCardâ€

Each Card represents **one semantic unit** (vocabulary, grammar marker, non-manual signal).
A Card contains:

* 1â€“3 short looping video clips (2â€“3 seconds each)
* minimal English gloss
* optional usage notes
* structured metadata (tags, difficulty, source)

Cards must be:

* filesystem-native
* human readable
* database-ready
* presentation-agnostic

## 4. Folder Structure (Source of Truth)

```
asl-motion-study/
â”œâ”€â”€ 00_INBOX/
â”‚   â””â”€â”€ raw_captures/
â”‚
â”œâ”€â”€ 01_CARDS/
â”‚   â”œâ”€â”€ vocab/
â”‚   â”‚   â””â”€â”€ from/
â”‚   â”‚       â”œâ”€â”€ clip_01.mp4
â”‚   â”‚       â”œâ”€â”€ clip_02.mp4
â”‚   â”‚       â”œâ”€â”€ meta.json
â”‚   â”‚       â””â”€â”€ notes.md
â”‚   â”‚
â”‚   â”œâ”€â”€ grammar/
â”‚   â”‚   â””â”€â”€ yes-no-questions-eyebrows/
â”‚   â”‚       â”œâ”€â”€ clip_01.mp4
â”‚   â”‚       â”œâ”€â”€ meta.json
â”‚   â”‚       â””â”€â”€ notes.md
â”‚
â”‚   â””â”€â”€ non_manual_markers/
â”‚
â”œâ”€â”€ 02_SOURCES/
â”‚   â””â”€â”€ <source_name>/
â”‚       â””â”€â”€ <date_topic>/
â”‚           â”œâ”€â”€ raw.mp4
â”‚           â”œâ”€â”€ transcript.txt
â”‚           â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ 03_EXPORTS/
â”‚   â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ anki/
â”‚   â””â”€â”€ pdf/
â”‚
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ card_meta.schema.json
â”‚
â””â”€â”€ README.md
```

## 5. Metadata Schema (v1)

Each Card includes a `meta.json`:

```json
{
  "id": "from",
  "type": "vocab",
  "gloss": "from",
  "difficulty": "beginner",
  "tags": [
    "handshape:flat",
    "location:neutral-space",
    "movement:outward",
    "nmm:none"
  ],
  "source": "ASL lesson <name>",
  "notes": "Directional sign; orientation matters."
}
```

This schema must remain stable as the project grows.

## 6. Workflow

### Capture

* Record short snippets into `00_INBOX/raw_captures/`
* No organization pressure at capture time

### Process

* Trim to 2â€“3 second loops
* Create Card folder
* Add `meta.json` + `notes.md`

### Use

* Review Cards locally
* Later render via web app / API

## 7. Non-Goals (Explicit)

* Full ASL transcription
* Grammar enforcement
* Curriculum completeness
* Performance optimization

This project prioritizes **clarity, motion fidelity, and future extensibility**.

## 8. Success Criteria

* Cards can be browsed and reviewed locally
* Motion conveys meaning without text
* Same Cards can later power: * a web app * spaced repetition * gesture-HCI experiments

# Recording & Format Decisions (Clear Answers)

## 1. Snagit vs OBS

### âœ… **Recommendation: Snagit (for now)**

**Why Snagit wins for this project:**

* fast capture â†’ low friction
* region selection is perfect for isolating signer
* great for **learning + iteration**
* minimal setup overhead

OBS is better for:

* live demos
* streaming
* complex layouts

But OBS adds cognitive overhead you *donâ€™t need* right now.
ğŸ‘‰ **Use Snagit for capture. Standardize later.**

## 2. Resolution / Size / Aspect Ratio

### âœ… **Recommended Standard**

* **Aspect ratio:** `1:1` (square)
* **Resolution:** `512 Ã— 512` or `640 Ã— 640`
* **Framerate:** `30 fps`

**Why square?**

* ideal for looping
* works everywhere (web, mobile, Anki)
* crops out irrelevant background
* future-proof for XR / HCI overlays

**Why not 1080p?**

* unnecessary for hand + face clarity
* bloats file size
* slows iteration

## 3. GIF vs MP4

### âŒ GIF (do not use)

* huge file sizes
* no temporal compression
* bad for subtle motion (hands, eyebrows)

### âœ… **MP4 (H.264 / H.265)**

MP4 gives:

* excellent compression
* smooth looping
* universal support
* easy conversion later

ğŸ‘‰ **Always record/export MP4.**

## 4. Best Compression Settings (High Quality, Small Size)

### Safe default (H.264)

```
Resolution: 512x512
Codec: H.264
CRF: 20â€“23
Preset: slow
FPS: 30
Audio: none
```

### Smaller files (optional later)

```
Codec: H.265 (HEVC)
CRF: 24â€“26
```

For 2â€“3 second clips, this yields:

* **50â€“150 KB per clip**
* no visible degradation for ASL motion

## Final Recommendation Summary

* âœ… **Snagit** for capture
* âœ… **Square video (512Ã—512, 30fps)**
* âœ… **MP4 only**
* âœ… **H.264 CRF ~22**
* âœ… Folder-first, schema-driven system
* ğŸš« No PDFs as primary artifacts
* ğŸš« No premature database